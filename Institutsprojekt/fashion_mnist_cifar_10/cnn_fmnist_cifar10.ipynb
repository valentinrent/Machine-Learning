{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Multilayer Perceptrons to Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will start with a simple Multilayer Perceptron (MLP) and then gradually build up to a Convolutional Neural Network (CNN) to classify the FashionMNIST and CIFAR10 datasets. We will use PyTorch to build and train the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\AppData\\Local\\Temp\\ipykernel_11680\\4098912036.py:9: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# Libraries to be imported, please make sure you have them installed\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.autonotebook import tqdm\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, we can use the GPU to accelerate the training process. We can check if a GPU is available and set the device accordingly. This will allow us to move the data and the model to the GPU. We check if a GPU is available and set the device accordingly. We also set the random seed for reproducibility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code cells, we define the training and evaluation functions for the models. They follow the same structure as in the previous notebook. However, there are some changes including the addition of metrics to measure the performance and the use of progress bars to track the training progress. They assist in monitoring the training process and help in debugging if the model is not learning as expected. \n",
    "\n",
    "For the progress bars, we use the `tqdm` library. You can install it using `!pip install tqdm`. You can read more about the library [here](https://github.com/tqdm/tqdm). The `tqdm` library provides a simple way to add progress bars to your loops. You can wrap any iterable with `tqdm(iterable)` to display a progress bar that updates in real time. In our case we wrap the `train_loader` and `test_loader` with `tqdm` to display the progress bars during training and testing. The progress bars iterate over the batches in the dataset and display the loss and the metrics for each batch.\n",
    "\n",
    "For the metrics, we use the `torchmetrics` library. You can install it using `!pip install torchmetrics`. You can read more about the library [here](https://torchmetrics.readthedocs.io/en/latest/). After each training epoch, as well as after testing the model on the test dataset, we want to output the following metrics for the model:\n",
    "- Accuracy\n",
    "- F1 score\n",
    "\n",
    "The Accuracy is the ratio of the number of correct predictions to the total number of predictions. It is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}}\n",
    "$$\n",
    "\n",
    "The F1 score is the harmonic mean of the precision and recall. It is defined as:\n",
    "\n",
    "$$\n",
    "\\text{F1 score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "where Precision is the ratio of the number of true positive predictions to the total number of positive predictions. It is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{Number of true positive predictions}}{\\text{Total number of positive predictions}}\n",
    "$$\n",
    "\n",
    "and Recall is the ratio of the number of true positive predictions to the total number of actual positive samples. It is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{Number of true positive predictions}}{\\text{Total number of actual positive samples}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, loss_fn, epochs, device=\"cpu\"):\n",
    "    model = model.to(device)  # Move the model to the device\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    # ToDo: Initialize the metrics\n",
    "    numclasses = len(train_loader.dataset.classes)\n",
    "    print(numclasses)\n",
    "    acc = Accuracy(task='multiclass', num_classes=numclasses).to(device)\n",
    "    f1 = F1Score(task='multiclass',num_classes=numclasses).to(device)\n",
    "\n",
    "    running_loss = []  # Initialize the running loss\n",
    "\n",
    "    progress_bar1 = tqdm(\n",
    "        range(epochs),\n",
    "        desc=\"Epochs [Loss: -,  Acc: -, AUROC: -, F1: -]\",\n",
    "        position=0,\n",
    "        leave=True,\n",
    "    )  # Progress bar for epochs\n",
    "\n",
    "    for _ in progress_bar1:\n",
    "        progress_bar2 = tqdm(\n",
    "            train_loader, desc=\"Loss: -\", position=1, leave=True\n",
    "        )  # Progress bar for batches\n",
    "\n",
    "        for x, y in progress_bar2:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # ToDo: Forward pass\n",
    "            f_x = model(x)\n",
    "            loss = loss_fn(f_x, y)\n",
    "\n",
    "            # ToDo: Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # ToDo: Update the metrics\n",
    "            acc.update(f_x, y)\n",
    "            f1.update(f_x, y)\n",
    "\n",
    "            running_loss.append(loss.item())  # Update the running loss\n",
    "            progress_bar2.set_description(desc=f\"Loss: {running_loss[-1]:.3f}\")\n",
    "\n",
    "        avg_loss = sum(running_loss) / len(running_loss)\n",
    "        running_loss = []\n",
    "        progress_bar1.set_description(\n",
    "            desc=f\"Epochs [Loss: {avg_loss:.3f},  Acc: {acc.compute():.3f}, F1: {f1.compute():.3f}]\"\n",
    "        )  # Update the progress bar description for epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()  # Decorator to disable gradient calculation\n",
    "def evaluate_model(model, test_loader, loss_fn, device=\"cpu\"):\n",
    "    model = model.to(device)  # Move the model to the device\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # ToDo: Initialize the metrics\n",
    "    numclasses = len(test_loader.dataset.classes)\n",
    "    acc = Accuracy(task='multiclass', num_classes=numclasses).to(device)\n",
    "    f1 = F1Score(task='multiclass',num_classes=numclasses).to(device)\n",
    "\n",
    "    running_loss = []  # Initialize the running loss\n",
    "\n",
    "    progress_bar = tqdm(test_loader, desc=\"Loss: -\", leave=True)\n",
    "\n",
    "    for x, y in progress_bar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # ToDo: Forward pass\n",
    "        f_x = model(x)\n",
    "        loss = loss_fn(f_x, y)\n",
    "\n",
    "        # ToDo: Update the metrics\n",
    "        acc.update(f_x, y)\n",
    "        f1.update(f_x, y)\n",
    "\n",
    "        running_loss.append(loss.item())  # Update the running loss\n",
    "        progress_bar.set_description(desc=f\"Loss: {running_loss[-1]:.3f}\")\n",
    "\n",
    "    avg_loss = sum(running_loss) / len(running_loss)\n",
    "    print(\n",
    "        f\"Evaluation Results: [Loss: {avg_loss:.3f},  Acc: {acc.compute():.3f}, F1: {f1.compute():.3f}]\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the FashionMNIST and CIFAR10 datasets using the `torchvision` library. It is a good practice to normalize the dataset by calculating the mean and standard deviation of the dataset and then using them to normalize the dataset. The mean and standard deviation for both the FashionMNIST and CIFAR10 datasets are provided below:\n",
    "\n",
    "- FashionMNIST:\n",
    "    - Mean: 0.2860\n",
    "    - Standard Deviation: 0.3530\n",
    "- CIFAR10:\n",
    "    - Mean: (0.4914, 0.4822, 0.4465)\n",
    "    - Standard Deviation: (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "Also, since our model expects the input to be tenors, we convert the images and labels to tensors. To convert the images to tensors and to normalize the dataset, we use the `transforms` module from the `torchvision` library. We use the `Compose` class to chain the transformations together. We first convert the images to tensors and then normalize the dataset using the mean and standard deviation of the dataset. We then pass the `Compose` object to the `transform` argument of the `Dataset` class to apply the transformations to the dataset.\n",
    "\n",
    "After loading the dataset, we create the data loaders using the `DataLoader` class. We pass the dataset and the batch size to the `DataLoader` class to create the data loaders. The batch size is a hyperparameter that determines the number of samples that will be passed through the model at once. A larger batch size can speed up the training process, but it requires more memory. A smaller batch size can slow down the training process, but it requires less memory. We set the batch size to 64 for both the FashionMNIST and CIFAR10 datasets, but you are free to experiment with different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FMNIST\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        # ToDo: Add image transformations\n",
    "        # 1) Convert images to tensors\n",
    "        # 2) Normalize the dataset\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.2860,), (0.3530,))\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "# ToDo: Download the training and test datasets\n",
    "fmnist_train_dataset = datasets.FashionMNIST(root=\"C:\\datasets\", train=True, transform=transform, download=True)\n",
    "fmnist_test_dataset =  datasets.FashionMNIST(root=\"C:\\datasets\", train=False, transform=transform, download=True)\n",
    "\n",
    "# ToDo: Prepare the data loaders\n",
    "fmnist_train_loader = torch.utils.data.DataLoader(fmnist_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "fmnist_test_loader = torch.utils.data.DataLoader(fmnist_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        # 1) Convert images to tensors\n",
    "        # 2) Normalize the dataset\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ToDo: Download the training and test datasets\n",
    "cifar10_train_dataset = datasets.CIFAR10(root=\"C:\\datasets\", train=True, transform=transform, download=True)\n",
    "cifar10_test_dataset = datasets.CIFAR10(root=\"C:\\datasets\", train=False, transform=transform, download=True)\n",
    "\n",
    "# ToDo: Prepare the data loaders\n",
    "cifar10_train_loader = torch.utils.data.DataLoader(cifar10_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "cifar10_test_loader = torch.utils.data.DataLoader(cifar10_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all our tasks involve image classification, we will use the same loss function for all the models. We will use the Cross Entropy Loss function, which is commonly used for classification tasks. It is defined as:\n",
    "\n",
    "$$\n",
    "L(y, \\hat{y}) = -\\sum_{i} y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "where $y_i$ is the true label and $\\hat{y}_i$ is the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Define Loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Stochastic Gradient Descent (SGD) and Adam ([link to paper](https://arxiv.org/abs/1412.6980)) optimizers in this notebook, but you can experiment with other optimizers like AdaGrad, RMSprop, etc. The learning rate is a hyperparameter that determines the step size at each iteration while moving toward a minimum of a loss function. In the SGD algorithm the learning $\\alpha$ rate is defined as: \n",
    "\n",
    "$$\n",
    "\\phi_{t+1} = \\phi_t - \\alpha \\nabla L(f(x_t; \\phi_t), y_t)\n",
    "$$\n",
    "\n",
    "where $\\phi_t$ are the current weights, $\\phi_{t+1}$ are the updated weights, $\\nabla L(f(x_t; \\phi_t), y_t)$ is the gradient of the loss function with respect to $\\phi_t$, $f(x_t; \\phi_t)$ is the prediction of the model for $x_t$, and $y_t$ is the true label of $x_t$.\n",
    "\n",
    "We set the learning rate to 0.001 for all the models, but you are free to experiment with different learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3  # Learning rate for the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One complete pass through the dataset is called an epoch. We train the model for a certain number of epochs. We set the number of epochs to 30 for all the models, but you are free to experiment with different numbers of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30 # Number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FashionMNIST with MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the MLP model for the FashionMNIST dataset. The model consists of **two hidden layers with ReLU activation functions and a final output layer with a softmax activation function**. The hyperparameters of the hidden layers are defined as follows:\n",
    "- Hidden Layer 1: width = 128\n",
    "- Hidden Layer 2: width = 64\n",
    "\n",
    "> Please consider that in PyTorch the softmax function is already applied in the CrossEntropy loss function.\n",
    "\n",
    "We then initialize the model and the optimizer. In this case, we use the Stochastic Gradient Descent (SGD) with default parameters and our defined learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            # ToDo:  Define the layers of the MLP\n",
    "            # ...\n",
    "            # Softmax is included in the loss function !\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ToDo: Forward pass\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "        \n",
    "\n",
    "model = MLP()\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "\n",
    "# ToDo: Define  Optimizer using the model parameters and the learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the entire pipeline\n",
    "train_model(model, fmnist_train_loader, optimizer, loss_fn, epochs=epochs)\n",
    "evaluate_model(model, fmnist_test_loader, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 with MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can train the MLP model on the CIFAR10 dataset, we need to modify the MLP model to accept the input shape of the CIFAR10 dataset. The CIFAR10 dataset consists of color images with a shape of (3, 32, 32). We need to modify the model to accept this input shape. Also, due to the high dimensionality of the CIFAR10 dataset, we need to increase the number of hidden layers and also the number of neurons in the hidden layers to enable the model to learn more complex patterns in the data. Our new model will consist of **three hidden layers with ReLU activation functions and a final output layer with a softmax activation function**. The hyperparameters of the hidden layers are defined as follows:\n",
    "- Hidden Layer 1: width = 256\n",
    "- Hidden Layer 2: width = 128\n",
    "- Hidden Layer 3: width = 64\n",
    "\n",
    "> Please consider that in PyTorch the softmax function is already applied in the CrossEntropy loss function.\n",
    "\n",
    "We then instantiate the model and define the optimizer. We use the same optimizer and learning rate as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            # ToDo:  Define the layers of the MLP\n",
    "            # ...\n",
    "            # Softmax is included in the loss function !\n",
    "            nn.Linear(3072, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ToDo: Forward pass\n",
    "        x = x.view(-1, 32*32*3)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MLP()\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "\n",
    "# ToDo: Define Optimizer using the model parameters and the learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the entire pipeline\n",
    "train_model(model, cifar10_train_loader, optimizer, loss_fn, device=device, epochs=epochs)\n",
    "evaluate_model(model, cifar10_test_loader, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "After training the MLP model on the datasets, please answer the following questions:\n",
    "\n",
    "1. What are the train- and test-accuracies of the MLP models?\n",
    "2. What are the train- and test-F1-scores of the MLP models?\n",
    "3. Does the MLP model generalize well on the datasets? Explain your answer.\n",
    "4. How does the MLP model perform on the CIFAR10 dataset compared to the FashionMNIST dataset?\n",
    "5. What are some possible explanations for differences in performance?\n",
    "6. Can we use the MLP model for datasets with higher resolution images? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "1. \n",
    "    1. MNIST: \n",
    "    2. Train: 79,4%\n",
    "    3. Test: 83,4%\n",
    "    1. CIFAR10:\n",
    "    2. Train: 39.1%\n",
    "    3. Test: 47.8%\n",
    "2. \n",
    "    1. MNIST: \n",
    "    2. Train: 0.794\n",
    "    3. Test: 0.835\n",
    "    1. CIFAR10:\n",
    "    2. Train: 0.391\n",
    "    3. Test: 0.478\n",
    "3. Generalization seems to be good since test data perfoms slightly better than training data\n",
    "4. The MLP performes approx. two times worse on the CIFAR10 dataset compared to FashionMNIST.\n",
    "5. The CIFAR10 dataset contains more complex images and features such as color are not considered.\n",
    "6. While it is possible, complexity will get very high making MLP's ineffecive \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 with Simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we introduce a simple Convolutional Neural Network (CNN) model for the CIFAR10 dataset. The model consists of **two convolutional layers with ReLU activation functions, followed by a max pooling layer, one fully connected layer with ReLU activation function, and a final output layer with a softmax activation function.** The hyperparameters of the hidden layers are defined as follows:\n",
    "- Convolutional Layer 1: out_channels = 32, kernel_size = 3\n",
    "- Max Pooling Layer: kernel_size = 2\n",
    "- Convolutional Layer 2: out_channels = 64, kernel_size = 3\n",
    "- Max Pooling Layer: kernel_size = 2\n",
    "- Fully Connected Layer: width = 64\n",
    "\n",
    "> Please consider that in PyTorch the softmax function is already applied in the CrossEntropy loss function.\n",
    "\n",
    "We then instantiate the model and define the optimizer. In this case, we use the Adam optimizer with default parameters and our defined learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            # ToDo: Define the layers of the CNN model\n",
    "            # ...\n",
    "            # Softmax is included in the loss function !\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ToDo: Forward pass\n",
    "        # ...\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "\n",
    "# ToDo: Define Optimizer using the model parameters and the learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the entire pipeline\n",
    "train_model(model, cifar10_train_loader, optimizer, loss_fn, device=device, epochs=epochs)\n",
    "evaluate_model(model, cifar10_test_loader, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "After training the simple CNN model on the CIFAR10 dataset, please answer the following questions:\n",
    "1. What are the train- and test-accuracies of the CNN models?\n",
    "CIFAR10:\n",
    "    Train: 79.4%\n",
    "    Test: 83.4%\n",
    "2. What are the train- and test-F1-scores of the CNN models?\n",
    "CIFAR10:\n",
    "    Train: 0.794\n",
    "    Test: 0.834\n",
    "3. Does the simple CNN model generalize well on the CIFAR10 dataset? Explain your answer.\n",
    "Accuracy and F1 of test data is higher than of training data -> Yes\n",
    "4. What improvements can be made to the simple CNN model to improve its generalization performance?\n",
    "More Channels ? More layers ?\n",
    "5. How does the simple CNN model perform on the CIFAR10 dataset compared to the MLP model?\n",
    "Much better with double the accuracy\n",
    "6. What are the advantages of using a CNN model over an MLP model for image classification tasks?\n",
    "CNN takes sourrounding of pixels into consideration and can detect features better \n",
    "7. What results do you expect if we use the CNN model for the FashionMNIST dataset?\n",
    "Even better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "1. \n",
    "    1. MNIST: \n",
    "    2. Train: 79,4%\n",
    "    3. Test: 83,4%\n",
    "    1. CIFAR10:\n",
    "    2. Train: 39.1%\n",
    "    3. Test: 47.8%\n",
    "2. \n",
    "    1. MNIST: \n",
    "    2. Train: 0.794\n",
    "    3. Test: 0.835\n",
    "    1. CIFAR10:\n",
    "    2. Train: 0.391\n",
    "    3. Test: 0.478\n",
    "3. Generalization seems to be good since test data perfoms slightly better than training data\n",
    "4. The MLP performes approx. two times worse on the CIFAR10 dataset compared to FashionMNIST.\n",
    "5. The CIFAR10 dataset contains more complex images and features such as color are not considered.\n",
    "6. While it is possible, complexity will get very high making MLP's ineffecive \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 with Modern CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sections, we worked with neural networks that are considered shallow by today's standards. In this final section we introduce a modern CNN model that is widely used for image classification tasks, namely the **ResNet18** model from the ResNet family. The ResNet18 model consists of **18 layers with residual connections**. You can read more about the ResNet18 model [here](https://arxiv.org/abs/1512.03385).\n",
    "\n",
    "The purpose of this section is to demonstrate the superior performance of deeper CNN models over shallow CNN models. We will train the ResNet18 model on the CIFAR10 dataset and compare its performance with the simple CNN model.\n",
    "\n",
    "The question may arise why we don't just add layers to our previous model until it is \"deep enough\". In general, while defining our own CNN model is a good exercise, using a pre-trained model like ResNet18 can save time and computational resources. For example, we can use the pre-trained model as a feature extractor and then train a small fully connected layer on top of it. This iknown as transfer learning, and it is a common technique used in practice. However, transfer learning is out of the scope of this notebook. Here, we will train the ResNet18 model from scratch. \n",
    "\n",
    "Instantiating the model is simple in PyTorch. It exists as predefined class in the `torchvision.models` module as well as in the `torch.hub` module. However, since the ResNet18 model was built for the ImageNet dataset, which consists of color images with a resolution of 224x224, we need to modify the model to accept the input shape of the CIFAR10 dataset. Furthermore, each image in ImageNet has 1000 classes, so we need to modify the output layer to have 10 classes for the CIFAR10 dataset.\n",
    "\n",
    "We then define the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\valen/.cache\\torch\\hub\\pytorch_vision_v0.9.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"pytorch/vision:v0.9.0\", \"resnet18\", weights=None)\n",
    "\n",
    "# Modify the first layer to accept 3 x 32 x 32 images\n",
    "# Hint: You can access the model layers and modify them\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "# Modify the last layer to have 10 classes\n",
    "# Hint: You can access the model layers and modify them\n",
    "model.fc = nn.Linear(512, 10)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "\n",
    "# ToDo: Define Optimizer using the model parameters and the learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs [Loss: -,  Acc: -, AUROC: -, F1: -]:   0%|          | 0/30 [00:00<?, ?it/s]c:\\VS_Code_Mach_Learing\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "c:\\VS_Code_Mach_Learing\\.conda\\Lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Loss: 1.285: 100%|██████████| 782/782 [00:43<00:00, 17.81it/s]\n",
      "Loss: 0.555:  42%|████▏     | 326/782 [00:17<00:24, 18.63it/s] 1/30 [00:43<21:13, 43.91s/it]\n",
      "Epochs [Loss: 1.154,  Acc: 0.587, F1: 0.587]:   3%|▎         | 1/30 [01:01<29:41, 61.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the entire pipeline\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcifar10_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m evaluate_model(model, cifar10_test_loader, loss_fn, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, optimizer, loss_fn, epochs, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m progress_bar2 \u001b[38;5;241m=\u001b[39m tqdm(\n\u001b[0;32m     22\u001b[0m     train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: -\u001b[39m\u001b[38;5;124m\"\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     23\u001b[0m )  \u001b[38;5;66;03m# Progress bar for batches\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m progress_bar2:\n\u001b[1;32m---> 26\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     27\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# ToDo: Forward pass\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the entire pipeline\n",
    "train_model(model, cifar10_train_loader, optimizer, loss_fn, device=device, epochs=epochs)\n",
    "evaluate_model(model, cifar10_test_loader, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "After training the ResNet18 model on the CIFAR10 dataset, please answer the following questions:\n",
    "1. What is the train- and test-accuracy of the ResNet18 model?\n",
    "Train: 94.4%\n",
    "Test: 81.1%\n",
    "2. What is the train- and test-F1-score of the ResNet18 model?\n",
    "Train: 94.4%\n",
    "Test: 81.1%\n",
    "3. Does the ResNet18 model generalize well on the CIFAR10 dataset? Explain your answer.\n",
    "Not that well bruv\n",
    "4. How does the ResNet18 model perform on the CIFAR10 dataset compared to the simple CNN model?\n",
    "Training much better/testing worse ?\n",
    "5. How many parameters does the ResNet18 model have compared to the simple CNN model? Is the difference reflected in the performance? How about the training time?\n",
    "Long training time / much more parameters\n",
    "6. Can we expect the same behavior if we created a deeper MLP model instead of using the ResNet18 model? Explain your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ToDo: Your answers here**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPSL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
